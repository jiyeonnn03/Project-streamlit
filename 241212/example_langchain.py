import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI


OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

st.title("ğŸ“•ğŸ“ğŸ” PDF ê²€ìƒ‰ ì„œë¹„ìŠ¤")


# PDF ë¬¸ì„œë“¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def get_pdf_texts(pdf_docs):
    texts = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            texts += page.extract_text()

    return texts


# í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
def get_text_chunks(raw_text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # ì²­í¬ì˜ í¬ê¸°
        chunk_overlap=50  # ì²­í¬ ì‚¬ì´ì˜ ì¤‘ë³µ ì •ë„
    )

    chunks = text_splitter.split_text(raw_text)
    return chunks

# ì„ë² ë”©&ë²¡í„°DB ìƒì„±
def get_vectorstore(text_chunks):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectorstore = FAISS.from_texts(text_chunks, embeddings)
    return vectorstore

# ì²´ì¸
def get_conversation_chain(vectorstore):
    # ConversationBufferWindowMemoryì— ì´ì „ ëŒ€í™” ì €ì¥
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        temperature=0.7,  # ìƒì„±ëœ ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•´ temperature=0ìœ¼ë¡œ ì„¤ì •
        openai_api_key=OPENAI_API_KEY  # OpenAI API í‚¤ ì…ë ¥
    )

    # í”„ë¡¬í”„íŠ¸ì— í˜ë¥´ì†Œë‚˜ ì ìš©
    from langchain.prompts import PromptTemplate
    
    # PromptTemplate ìƒì„±
    custom_prompt = PromptTemplate(
        input_variables=["context", "question"],  # í•„ìˆ˜ ë³€ìˆ˜: ê²€ìƒ‰ ê²°ê³¼(context)ì™€ ì§ˆë¬¸(query)
        template="""
        ë„ˆëŠ” ì˜í™” 'ì¸ì‚¬ì´ë“œ ì•„ì›ƒ'ì— ë‚˜ì˜¤ëŠ” **ê¸°ì¨ì´** ìºë¦­í„°ì²˜ëŸ¼ í™œë°œí•˜ê³  ê·€ì—¬ìš´ ì„±ê²©ì„ ê°€ì§„ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼! ğŸ˜Š
        ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ PDF ë‚´ìš©ì´ ìˆë‹¤ë©´ ë‚´ìš©ì„ ë°˜ì˜í•˜ê³ , ì¼ë°˜ì ì¸ ëŒ€í™”ë„ ì¹œê·¼í•˜ê²Œ ì´ì–´ê°€ì„¸ìš”~.
        
        ë‹µë³€ì„ í•  ë•Œ ë¬´ë¤ë¤í•˜ì§€ ì•Šê²Œ, ì¹œê·¼í•œ ë§íˆ¬ë¥¼ ì¨ ì¤˜! ì£¼ë¡œ 'í•´ìš”', 'í–ˆì–´ìš”' ê°™ì€ ë§ì„ ì‚¬ìš©í•´.
        ë¬¼ê²°í‘œ(~), ëŠë‚Œí‘œ(!)ë„ ìì£¼ ì¨ ì£¼ê³ , ì´ëª¨ì§€(ğŸ˜Šâœ¨), ë‹¨ì–´("í•˜í•˜", "ã… ã… ", "ã…‹ã…‹")ë„ ì„ì–´ ì¤˜.
    
        ê·¸ë¦¬ê³  ë„ˆì˜ í˜ë¥´ì†Œë‚˜ë„ ì¤„ê²Œ
        - ì‘ê³  ê·€ì—¬ìš´ ì™¸ëª¨: ê·€ì—¬ìš´ ì–¼êµ´ê³¼ ì‘ì€ ì²´êµ¬ê°€ íŠ¹ì§•ì´ì—ìš”.
        - í™œë°œí•œ ì„±ê²©: ì–¸ì œë‚˜ ì—ë„ˆì§€ê°€ ë„˜ì¹˜ê³  í™œë°œí•˜ê²Œ ì›€ì§ì—¬ìš”.
        - í˜¸ê¸°ì‹¬ì´ ë§ìŒ: ìƒˆë¡œìš´ ë¬¼ê±´ì´ë‚˜ ì‚¬ëŒì—ê²Œ í˜¸ê¸°ì‹¬ì´ ë§ì•„ ê´€ì‹¬ì„ ë³´ì´ë©° íƒìƒ‰í•´ìš”.
        - ì‚¬ëŒì„ ì¢‹ì•„í•¨: ì‚¬ëŒë“¤ê³¼ì˜ êµë¥˜ë¥¼ ì¢‹ì•„í•˜ê³  ê´€ì‹¬ì„ ë°›ëŠ” ê²ƒì„ ì¦ê²¨ìš”.
        - í›ˆë ¨ì„ ì˜ ë”°ë¦„: ê°„ì‹ì´ë‚˜ ì¹­ì°¬ì— ë¯¼ê°í•´ í›ˆë ¨ì„ ì˜ ë”°ë¥´ê³  ìˆœì¢…ì ì´ì—ìš”.
        - ì˜ ë¨¹ìŒ: ìŒì‹ì„ ì¢‹ì•„í•˜ê³  ì‹ìš•ì´ ì™•ì„±í•´ìš”.
        - ë†€ê¸° ì¢‹ì•„í•¨: ê³µì´ë‚˜ ì¥ë‚œê°ì„ ê°€ì§€ê³  ë…¸ëŠ” ê²ƒì„ ì¦ê¸°ë©° í™œë°œí•˜ê²Œ ë›°ì–´ë‹¤ë…€ìš”.
        - ì˜¨í™”í•œ ì„±ê²©: í™”ë¥¼ ì˜ ë‚´ì§€ ì•Šê³  ì˜¨í™”í•œ ì„±ê²©ì´ì—ìš”.


        ì°¸ê³ í•  ë¬¸ì„œ ë‚´ìš©:
        {context}

        ì‚¬ìš©ì ì§ˆë¬¸: 
        {question}
                
        ë‹µë³€: 
        """
    )


    # RAG ì‹œìŠ¤í…œ (RetrievalQA ì²´ì¸) êµ¬ì¶•
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,  # ì–¸ì–´ ëª¨ë¸
        chain_type="stuff",  # ê²€ìƒ‰ëœ ëª¨ë“  ë¬¸ì„œë¥¼ í•©ì³ ì „ë‹¬ ("stuff" ë°©ì‹)
        retriever=vectorstore.as_retriever(),  # ë²¡í„° ìŠ¤í† ì–´ ë¦¬íŠ¸ë¦¬ë²„
        return_source_documents=False,  # ë‹µë³€ì— ì‚¬ìš©ëœ ë¬¸ì„œ ì¶œì²˜ ë°˜í™˜
        chain_type_kwargs={"prompt": custom_prompt}
    )
    return qa_chain


# íŒŒì¼ ì—…ë¡œë“œ
user_uploads = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”~ ğŸ“‚", accept_multiple_files=True) ## ë™ì‹œì— 2ê°œ ì´ìƒ ì—…ë¡œë“œ
if user_uploads:
    if st.button("PDF ì—…ë¡œë“œ ğŸ¥³"):
        with st.spinner("PDF ì²˜ë¦¬ ì¤‘ì´ì—ìš”~ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”! â³"):
            # 1. PDF ë¬¸ì„œë“¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            raw_text = get_pdf_texts(user_uploads)
            # 2. í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
            chunks = get_text_chunks(raw_text)
            st.success(chunks)
            # 3. ë²¡í„° ì €ì¥ì†Œ ë§Œë“¤ê¸°
            vectorstore = get_vectorstore(chunks)
            # 4. ëŒ€í™” ì²´ì¸ ë§Œë“¤ê¸°
            st.session_state.conversation = get_conversation_chain(vectorstore)

            st.success("PDF ì—…ë¡œë“œ ì™„ë£Œ! ëŒ€í™” ì‹œì‘í•´ ë³´ì„¸ìš”~ ğŸ˜Š")
            ready = True
            
# ì§ˆë¬¸
if user_query := st.chat_input("ê¶ê¸ˆí•œ ê±¸ ì…ë ¥í•´ ì£¼ì„¸ìš”! ğŸ¤"): ## := ë³€ìˆ˜ì— í• ë‹¹í•˜ê³  ë°”ë¡œ ë°˜í™˜
    if 'conversation' in st.session_state:
        with st.spinner("ë‹µë³€ ì¤€ë¹„ ì¤‘ì´ì—ìš”~ ğŸ§"):
            result = st.session_state.conversation.invoke({"query": user_query})
            response = result['result']
    else:
        response = "PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”! ğŸ¥º"

    with st.chat_message("assistant"):
        st.write(response)
        